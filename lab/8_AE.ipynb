{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab. 8 Autoencoders\n",
    "\n",
    "![Auto-encoder](utils/ae.png)\n",
    "\n",
    "\n",
    "\"Vanilla\" autoenkodery minimalizują tzw. _reconstruction error_, najczęściej wyrażony w postaci błędu średniokwadratowego liczonego pomiędzy oryginalnym wejściem i rekonstrukcją.\n",
    "\n",
    "<font size=4>\n",
    "$$ \\mathcal{L}(x, dec(enc(x))) = ||x - dec(enc(x))||^2 $$\n",
    "</font>\n",
    "\n",
    "Enkoder i dekoder mogą być dowolnymi sieciami neuronowymi, najczęściej jednak dekoder składam się z tych samych transformacji co enkoder w odwrtonej kolejności.  \n",
    "\n",
    "**Pytanie:** Co mogłoby się stać gdybyśmy nie \"zwężali\" enkodera? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup i dane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from utils.draw_utils import plot_digits\n",
    "\n",
    "import torch\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "torch.manual_seed(1337) \n",
    "batch_size = 64 \n",
    "transforms = Compose([ToTensor(), Lambda(lambda x: x.flatten())])\n",
    "\n",
    "# Mnist dataset\n",
    "train_data = MNIST(root='./data/', \n",
    "                   train=True, \n",
    "                   transform=transforms,    \n",
    "                   download=True) # change to false if you already have the data\n",
    "\n",
    "# Data Loader for easy mini-batch return in training, the image batch shape will be (50, 1, 28, 28)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 1: Vanilla Autoencoder\n",
    "\n",
    "Zaimplementować Autoenkoder z 5 warstwami liniowymi (z nieliniową aktywacją np. `tanh`) w enkoderze: \n",
    "   * wejściowa (rozmiar cyfry z MNISTA)\n",
    "   * rozmiaru 128\n",
    "   * rozmiaru 64\n",
    "   * rozmiaru 12\n",
    "   * rozmiaru `latent_dim`\n",
    "oraz dekoderem z dokładnie odwrotnym przekształceniem.\n",
    "    \n",
    "**Pytanie:** Jaka powinna być funkcja aktywacji na wyjściu dekodera? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, latent_dim):\n",
    "        \n",
    "        super(AutoEncoder, self).__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        self.encoder = ???\n",
    "        self.decoder = ???\n",
    "        \n",
    "        \n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "    \n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ??? # encode and decode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 2: Pętla Uczenia\n",
    "Uzupełnić brakujące fragmenty kodu uczenia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "epochs = 10\n",
    "lr = 0.005 \n",
    "n_plots = 5\n",
    "\n",
    "# prepare original data for plotting\n",
    "view_data = train_data.train_data[:n_plots].view(-1, 28*28).type(torch.FloatTensor) / 255.\n",
    "\n",
    "autoencoder = AutoEncoder(latent_dim=3)\n",
    "\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=lr)\n",
    "loss_func = ??? # MSE loss function\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for step, (x, y) in enumerate(train_loader):\n",
    "\n",
    "        encoded, decoded = ??? \n",
    "\n",
    "        loss = ??? # calculate loss\n",
    "        optimizer.zero_grad()   # clear gradients for this training step\n",
    "        loss.backward()         # backpropagation, compute gradients\n",
    "        optimizer.step()        # apply gradients\n",
    "\n",
    "        if step % 500 == 0 and epoch in [0, 5, epochs - 1]:\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.item())\n",
    "\n",
    "            # plotting decoded image (second row)\n",
    "            _, decoded_data = autoencoder(view_data)\n",
    "            \n",
    "            plot_digits(view_data, decoded_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 3: \"Generowanie\" z Autoenkodera\n",
    "\n",
    "Teoretycznie nasz \"vanilla\" autoenkoder nie ma naturalnych właściwości generatywnych (więcej w przyszłości przy VAE), ale mimo to spróbujmy wygenerować z niego nowe przykłady.\n",
    "\n",
    "1. Załóżmy, że nasz autoenkoder układa dane \"w środku\" w rozkład normalny. Waszym zadaniem jest oszacowanie średniej i wariancji tego rozkładu dla `n` przykładów ze zbioru trenującego. Należy to zrobić na podstawie części zbioru trenującego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "n = 500\n",
    "\n",
    "for step, (x, y) in enumerate(train_loader):\n",
    "    \n",
    "    if len(samples) > n:\n",
    "        break\n",
    "    \n",
    "    # encode the points into the latent space and save for later estimation\n",
    "    ???\n",
    "    \n",
    "    \n",
    "sampled_z = np.concatenate(samples, axis=0)\n",
    "\n",
    "# compute mean and std of the empirical distribution in the latent space \n",
    "mean_z = ???\n",
    "std_z = ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Używając rozkładu normalnego sparametryzowanego policzonymi momentami wylosuj kilka przykład i zwizualizuj ich rekonstrukcje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_sampled = ??? # sample 5 points in the latent space\n",
    "x_decoded = ??? # decode the sampled points\n",
    "\n",
    "plot_digits(x_decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 4. Interpolacja\n",
    "\n",
    "Dla kilku przykładów ze zbioru trenującego zaimplementuj interpolacje pomiedzy parą punktów w przestrzeni _latent_, następnie zdekoduj te interpolacje i zwizualizuj wynik. Dla przypomnienie, liniowa interpolacja:\n",
    "\n",
    "<br>\n",
    "\n",
    "<font size=4>\n",
    "$$ \\forall \\lambda \\in [0,1] \\quad f_L(x_1, x_2, \\lambda) =  (1 - \\lambda) x_1 + \\lambda x_2 $$\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_interpolations = 5\n",
    "\n",
    "for step, (x, y) in enumerate(train_loader):\n",
    "    if step > n_interpolations:\n",
    "        break\n",
    "    \n",
    "    x_1 = x[0, :]\n",
    "    x_2 = x[1, :]\n",
    "    \n",
    "    z_1 = autoencoder.encode(x_1)\n",
    "    z_2 = autoencoder.encode(x_2)\n",
    "    \n",
    "    x_interpolated = []\n",
    "    \n",
    "    for i, alpha in enumerate(np.linspace(0, 1, 10)):\n",
    "        z_int = ??? # interpolate in the latent space\n",
    "        x_int = ??? # decode the interpolated sample\n",
    "        \n",
    "        x_interpolated.append(x_int)\n",
    "    \n",
    "    x_interpolated = torch.stack(x_interpolated, dim=0)\n",
    "    \n",
    "    plot_digits(x_interpolated)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
