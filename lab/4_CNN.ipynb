{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4. Konwolucje\n",
    "\n",
    "Zadanie dla Państwa na te ćwiczenia (z dokończeniem jako praca domowa) to implementacja funkcji konwolucji oraz max pooling dla obrazów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploting\n",
    "%matplotlib inline\n",
    "# imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading\n",
    "cifar_sample = np.load('utils/cifar_sample.npy')\n",
    "# get a first random image\n",
    "np_image = cifar_sample[0]\n",
    "# this should plot a blurry frog\n",
    "plt.imshow(np_image.transpose(1,2,0)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wzory na rozmiary\n",
    "**Pytanie 1**: Jaki będzie rozmiar obrazka na wyjściu konwolucji/poolingu przy parametrach poniżej.  \n",
    "**Uwaga**: zarówno we wzorach jak i w kodzie używana jest torchowa konwencja *channel first*.\n",
    "\n",
    "Stride: $ \\hspace{95px} S $  \n",
    "Padding: $ \\hspace{80px} P $  \n",
    "Obrazek wejściowy: $ \\hspace{12px} C_i \\times H_i \\times W_i$  \n",
    "Filtry: $ \\hspace{100px} K \\times C_f \\times F \\times F $  \n",
    "\n",
    "Gdzie: $C_i$ to liczba kanału obrazu wejściowego, $H_i, W_i$ to odpowiednio wysokość i szerokość obrazu wejściowego. $K$ to liczba filtrów, $C_f$ liczba kanałów w każdym filtrze, $F$ to zarówno wysokość jak i szerokość filtra (rozważami tylko filtry kwadratowe).\n",
    "\n",
    "Obrazek wyjściowy: $ \\hspace{15px} C_o \\times H_o \\times W_o $  \n",
    "\n",
    "\n",
    "$ \\hspace{140px} C_o = ??? $  \n",
    "$ \\hspace{140px} H_o = ??? $  \n",
    "$ \\hspace{140px} W_o = ??? $  \n",
    "\n",
    "**Pytanie 2**: Ile wag (floatów) ma taka warstwa konwolucyja?  \n",
    "\n",
    "### Wizualna pomoc do konwolucji\n",
    "[Źródło](http://cs231n.github.io/convolutional-networks/)\n",
    "\n",
    "<img src=\"./utils/cnn.gif\"></img>\n",
    "\n",
    "### Zadanie\n",
    "Zadaniem jest zaimplementowanie funkcji konwolucji i poolingu dla obrazku 2D. Implementacja nie musi być optymalna pod względem złożoności czasowej (tzn. można/zaleca się używanie pętli). \n",
    "\n",
    "Warunkiem zaliczenia zadania jest przejście komórek testowych dla konwolucji i poolingu. W razie problemów polecam zacząć od poolingu, który w idea jest podobny do konwolucji, lecz mniej skomplikowany.\n",
    "\n",
    "### Konwolucja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution(image: torch.tensor, \n",
    "                filters: torch.tensor, \n",
    "                bias: torch.tensor, \n",
    "                stride: int = 1, \n",
    "                padding: int = 1):\n",
    "    \"\"\"\n",
    "    :param image: torch.Tensor \n",
    "        Input image of shape (C, H, W)\n",
    "    :param filters: torch.Tensor \n",
    "        Filters to use in convolution of shape (K, C, F, F)\n",
    "    :param bias: torch.Tensor \n",
    "        Bias vector of shape (K,)\n",
    "    :param stride: int\n",
    "        Stride to use in convolution\n",
    "    :param padding: int\n",
    "       Zero-padding to add on all sides of the image \n",
    "    \"\"\"\n",
    "    # get image dimensions\n",
    "    img_channels, img_height, img_width = image.shape \n",
    "    n_filters, filter_channels, filter_size, filter_size = filters.shape \n",
    "    # calculate the dimensions of the output image\n",
    "    out_height = ???\n",
    "    out_width = ???\n",
    "    out_channels = ???\n",
    "    \n",
    "    ### YOUR CODE HERE ###\n",
    "                \n",
    "    return ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Convolution Test ### \n",
    "\n",
    "from itertools import product\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "# cast the frog to tensor\n",
    "image = torch.tensor(np_image)\n",
    "# preapre parameters for testing\n",
    "paddings = [0, 1, 2, 3]\n",
    "strides = [1, 2, 3, 4]\n",
    "filters = [(torch.randn((2,3,3,3)), torch.zeros((2))),\n",
    "           (torch.randn((2,3,5,5)), torch.zeros((2))),\n",
    "           (torch.randn((5,3,1,1)), torch.zeros((5)))]\n",
    "\n",
    "# test all combinations\n",
    "for (filt, bias), stride, padding in tqdm(product(filters, strides, paddings), total=4*4*3):\n",
    "    # your convolution\n",
    "    out = convolution(image, filt, bias, stride=stride, padding=padding)\n",
    "    # PyTorch equivalent\n",
    "    out_torch = torch.conv2d(input=image.unsqueeze(0), weight=filt, bias=bias, padding=padding, stride=stride)\n",
    "    # asserts\n",
    "    assert out_torch.squeeze().shape == out.shape\n",
    "    assert torch.allclose(out, out_torch.squeeze(), atol=1e-5, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pooling(image: torch.tensor, \n",
    "                kernel_size: int, \n",
    "                stride: int = 1, \n",
    "                padding: int = 1):\n",
    "    \"\"\"\n",
    "    :param image: torch.Tensor \n",
    "        Input image of shape (C, H, W)\n",
    "    :param kernel_size: int \n",
    "        Size of the square pooling kernel\n",
    "    :param stride: int\n",
    "        Stride to use in pooling\n",
    "    :param padding: int\n",
    "       Zero-padding to add on all sides of the image \n",
    "    \"\"\"\n",
    "    # get image dimensions\n",
    "    img_channels, img_height, img_width = image.shape\n",
    "    # calculate the dimensions of the output image\n",
    "    out_height = ???\n",
    "    out_width = ???\n",
    "    out_channels = ???\n",
    "\n",
    "    ### YOUR CODE HERE ###\n",
    "\n",
    "    return ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Max Pooling Test ###\n",
    "\n",
    "from itertools import product\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "# cast the frog to tensor\n",
    "image = torch.tensor(np_image)\n",
    "# preapre parameters for testing\n",
    "kernel_sizes = [2, 3, 4]\n",
    "paddings = [0, 1]\n",
    "strides = [1, 2, 3, 4]\n",
    "\n",
    "# test all combinations\n",
    "for kernel_size, stride, padding in tqdm(product(kernel_sizes, strides, paddings), total=3*2*4):\n",
    "    # your pooling\n",
    "    out = max_pooling(image, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "    # PyTorch equivalent\n",
    "    out_torch = torch.nn.functional.max_pool2d(input=image.unsqueeze(0), kernel_size=kernel_size, padding=padding, stride=stride)\n",
    "    # asserts\n",
    "    assert out_torch.squeeze().shape == out.shape\n",
    "    assert torch.allclose(out, out_torch.squeeze(), atol=1e-5, rtol=1e-5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
