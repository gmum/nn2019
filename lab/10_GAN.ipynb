{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 10. Generative Adversarial Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](utils/gan.png)\n",
    "\n",
    "## Generator Loss\n",
    "\n",
    "![](utils/gan_loss.png)\n",
    "\n",
    "## Discriminator Objective\n",
    "\n",
    "![](utils/disc_loss.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "\n",
    "import torch\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose, Normalize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "torch.manual_seed(1337) \n",
    "batch_size = 64 \n",
    "transforms = Compose([ToTensor(), \n",
    "                      Normalize((.5, .5, .5), (.5, .5, .5)), \n",
    "                      Lambda(lambda x: x.flatten())])\n",
    "\n",
    "# Mnist dataset\n",
    "train_data = MNIST(root='./data/', \n",
    "                   train=True, \n",
    "                   transform=transforms,    \n",
    "                   download=True) # change to false if you already have the data\n",
    "\n",
    "# Data Loader for easy mini-batch return in training, the image batch shape will be (50, 1, 28, 28)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "def plot(imgs):\n",
    "    \n",
    "    display.clear_output()\n",
    "    fig = plt.figure(figsize=(3 * num_test_samples, 5))\n",
    "\n",
    "    for i in range(num_test_samples):\n",
    "        ax = fig.add_subplot(1, num_test_samples, i+1)\n",
    "        ax.imshow(imgs[i], cmap='gray')\n",
    "        \n",
    "    display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sieci\n",
    "\n",
    "**Zadanie 1:** Zaimplementować Generator i Dyskruminator, generator ma się składać z warstw:\n",
    "* wejściowa: rozmiar wektora szumu (100)\n",
    "* 256\n",
    "* 512\n",
    "* 1024\n",
    "* rozmiar MNISTA (784)\n",
    "\n",
    "Dyskryminator powinien być odwortnośią generator pod względem rozmiaru wartsw, z tą różnicą, że jest wyjściem nie będzie szum rozmiaru 100 tylko logit do klasyfikacji binarnej. Dodatkowo w dyskryminatorze można użyć Dropoutu o wartości 0.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        ???\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        ???\n",
    "\n",
    "    def forward(self, x):\n",
    "        ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "# Optimizers\n",
    "g_optimizer = torch.optim.Adam(generator.parameters(), lr=0.0002)\n",
    "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "\n",
    "# Loss function\n",
    "loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trenowanie\n",
    "\n",
    "**Zadanie 2:** Uzupełnić brakujący kod w funkcjach do uczenia sieci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(optimizer, real_x, fake_x):\n",
    "    \n",
    "    # reset gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # do prediction on real data\n",
    "    ???\n",
    "    # Calculate error and backpropagate\n",
    "    error_real = ???\n",
    "    error_real.backward()\n",
    "\n",
    "    # do prediction on fake data\n",
    "    ???\n",
    "    # calculate error and backpropagate\n",
    "    error_fake = ???\n",
    "    error_fake.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    return error_real + error_fake\n",
    "\n",
    "def train_generator(optimizer, fake_x):\n",
    "\n",
    "    # reset gradients\n",
    "    optimizer.zero_grad()\n",
    "    # do prediction on fake data\n",
    "    ???\n",
    "    # calculate error and backpropagate\n",
    "    error = ???\n",
    "    error.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Petla Uczenia\n",
    "**Zadanie 3:** Uzupełnić brakujące elementy pętli uczenia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_test_samples = 5\n",
    "test_noise = torch.randn(num_test_samples, 100)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (real_batch, _) in enumerate(train_loader):\n",
    "        \n",
    "        batch_size = real_batch.shape[0]\n",
    "        \n",
    "        # generate fake data and train discriminator\n",
    "        fake_data = ???\n",
    "        # train the network\n",
    "        d_error = train_discriminator(???)\n",
    "\n",
    "        # generate fake data and train discriminator\n",
    "        fake_data = ???\n",
    "        # train the network\n",
    "        g_error = train_generator(???)\n",
    "\n",
    "        if i % 200 == 0:\n",
    "            test_images = generator(test_noise).view(-1, 28, 28).data.cpu()\n",
    "            plot(test_images)\n",
    "             \n",
    "            print(f\"Epoch: {epoch} Iter: {i}/{len(train_loader)}, G-error: {g_error.item()} D-error: {d_error.item()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
