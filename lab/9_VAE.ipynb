{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Variational Autoencoder\n",
    "\n",
    "Tym razem zajmiemy się modelem VAE. W porównaniu do zwykłego autoenkodera, VAE w warstwie latent space próbuje utrzymać rozkład normalny. Dzieje się to dzięki dwuczęściowej funkcji kosztu, która z jednej strony jest kosztem rekonstrukcji podobnym do rekonstrukcji autoenkodera, z drugiej strony porównuje latent space z próbkowanym rozkładem normalnym:\n",
    "\n",
    "$$ \\mathcal{L}(X, z) = \\mathbb{E}[\\log P(X|z)] - D_{KL}[Q(z|X) || P(z)] $$\n",
    "\n",
    "- $P(X|z)$ - rozkład generowanych danych przy danej zmiennej ukrytej $z$ (dekoder)\n",
    "- $P(z)$ - rozkład prawdopodobieństwa zmiennej ukrytej\n",
    "- $Q(z|X)$ - rozkład zmiennej ukrytej przy danym $X$ (enkoder)\n",
    "\n",
    "Pierwszą część funkcji kosztu można obliczyć przy pomocy kosztu regresji logistycznej (binarna entropia krzyżowa). Drugą część można rozpisać:\n",
    "\n",
    "$$ D_{KL}[N(\\mu(X), \\Sigma(X)) || N(0, 1)] = \\frac{1}{2} \\sum_k \\left(\\exp(\\Sigma(X)) + \\mu^2(X) - 1 - \\Sigma(X)\\right)$$\n",
    "\n",
    "![VAE](utils/VAE.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from utils.draw_utils import plot_digits\n",
    "\n",
    "import torch\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "torch.manual_seed(1337) \n",
    "batch_size = 64 \n",
    "transforms = Compose([ToTensor(), Lambda(lambda x: x.flatten())])\n",
    "\n",
    "# Mnist dataset\n",
    "train_data = MNIST(root='./data/', \n",
    "                   train=True, \n",
    "                   transform=transforms,    \n",
    "                   download=True) # change to false if you already have the data\n",
    "\n",
    "# Data Loader for easy mini-batch return in training, the image batch shape will be (50, 1, 28, 28)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 1. VAE\n",
    "\n",
    "Zaimplementować VAE, nadbudowując kod z ostatnich zajęć. Autoenkoder powinien składać się z warstw liniowych (z nieliniową aktywacją np. `tanh`) w enkoderze: \n",
    "   * wejściowa (rozmiar cyfry z MNISTA)\n",
    "   * rozmiaru 128\n",
    "   * rozmiaru 64\n",
    "   * rozmiaru 12\n",
    "   * 2 warstw rozmiaru `latent_dim` odpowiadająych średniej $\\mu$ i wariancji $\\Sigma$\n",
    "   \n",
    "oraz reparametryzacji obliczającej $z$ na podstawie $\\mu$ i $\\Sigma$, oraz dekodera z dokładnie odwrotnym przekształceniem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, latent_dim):\n",
    "        \n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        D = latent_dim\n",
    "        self.encoder = ???\n",
    "        self.mu_layer = ???\n",
    "        self.var_layer = ???\n",
    "        self.decoder = ???\n",
    "        \n",
    "    def reparametrize(self, mu, logvar):\n",
    "        ??? # use reparametrization trick\n",
    "    \n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "    \n",
    "    def encode(self, x):\n",
    "        enc = self.encoder(x)\n",
    "        return self.mu_layer(enc), self.var_layer(enc)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ??? # encode, reparametrize, and decode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 2: Pętla Uczenia\n",
    "\n",
    "Uzupełnić brakujące fragmenty kodu uczenia oraz funkcji kosztu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "epochs = 10\n",
    "LR = 0.005         # learning rate\n",
    "n_plots = 5\n",
    "latent_dim = 3\n",
    "\n",
    "# prepare original data for plotting\n",
    "view_data = train_data.data[:n_plots].view(-1, 28*28).type(torch.FloatTensor) / 255.\n",
    "\n",
    "autoencoder = VAE(latent_dim = latent_dim)\n",
    "\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=LR)\n",
    "loss_func = torch.nn.MSELoss() # ??? # Use MSE loss function\n",
    "\n",
    "def loss_func(x_decoded, x, z_mu, z_var):\n",
    "    BCE = ??? # use binary cross entropy as reconstruction loss\n",
    "    KLD = ??? # implement Kullback-Leibler divergence (formula above)\n",
    "\n",
    "    return BCE + KLD\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for step, (x, y) in enumerate(train_loader):\n",
    "\n",
    "        encoded, decoded, mu, var = ??? \n",
    "\n",
    "        loss = ??? # calculate loss\n",
    "        optimizer.zero_grad()   # clear gradients for this training step\n",
    "        loss.backward()         # backpropagation, compute gradients\n",
    "        optimizer.step()        # apply gradients\n",
    "\n",
    "        if step % 500 == 0 and epoch in [0, 5, epochs - 1]:\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.item())\n",
    "\n",
    "            # plotting decoded image (second row)\n",
    "            _, decoded_data, _, _ = autoencoder(view_data)\n",
    "            \n",
    "            plot_digits(view_data, decoded_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wizualizacja warstwy ukrytej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "for step, (x, y) in enumerate(train_loader):\n",
    "    z = autoencoder(x)[0].detach().numpy()\n",
    "    ax.scatter(z[:, 0], z[:, 1], z[:, 2], c = y)\n",
    "    if step == 10:\n",
    "        break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 3: Generowanie\n",
    "\n",
    "Wylosować 5 punktów z rozkładu N(0,1) i wygenerować z nich cyfry MNIST przy pomocy dekodera. Teraz już nie musimy liczyć statystyk latent space'a, bo znamy rozkład zmiennej $z$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "z_sampled = ??? # sample 5 points in the latent space\n",
    "x_decoded = ??? # decode the sampled points\n",
    "\n",
    "plot_digits(x_decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 4: Interpolacja\n",
    "\n",
    "Analogicznie do przykładu z poprzednich zajęć pokazać interpolację między cyframi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "n_interpolations = 5\n",
    "\n",
    "for step, (x, y) in enumerate(train_loader):\n",
    "    if step > n_interpolations:\n",
    "        break\n",
    "    \n",
    "    x_a = x[0, :]\n",
    "    x_b = x[1, :]\n",
    "    \n",
    "    mu_a, var_a = autoencoder.encode(x_a)\n",
    "    z_a = autoencoder.reparametrize(mu_a, var_a)\n",
    "    mu_b, var_b = autoencoder.encode(x_b)\n",
    "    z_b = autoencoder.reparametrize(mu_b, var_b)\n",
    "    \n",
    "    x_interpolated = []\n",
    "    \n",
    "    for i, alpha in enumerate(np.linspace(0, 1, 10)):\n",
    "        z_int = ??? # interpolate in the latent space\n",
    "        x_int = ??? # decode the interpolated sample\n",
    "        \n",
    "        x_interpolated.append(x_int)\n",
    "    \n",
    "    x_interpolated = torch.stack(x_interpolated, dim=0)\n",
    "    \n",
    "    plot_digits(x_interpolated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nn2019]",
   "language": "python",
   "name": "conda-env-nn2019-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
