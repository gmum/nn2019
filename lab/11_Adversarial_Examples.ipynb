{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wczytanie zbioru danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "import torch\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor, Compose, Normalize, Resize\n",
    "from torchvision.models import resnet18\n",
    "from tqdm.autonotebook import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337) \n",
    "\n",
    "batch_size = 64 \n",
    "transforms = Compose([Resize((224, 224)),\n",
    "                      ToTensor(), \n",
    "                      Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "# Mnist dataset\n",
    "train_data = MNIST(root='./data/', \n",
    "                   train=True, \n",
    "                   transform=transforms,    \n",
    "                   download=True)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_data = MNIST(root='./data/', \n",
    "                 train=False, \n",
    "                 transform=transforms, \n",
    "                 download=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning\n",
    "\n",
    "**Zadanie 1.** Proszę wymienić warstwę wejściową i wyjściową wczytanej sieci ResNet. \n",
    "\n",
    "- Wejście powinno mieć 1 kanał wejściowy zamiast 3,\n",
    "- wyjście powinno być 10-klasowe.\n",
    "\n",
    "*Hint:* Nazwy warstw można otrzymać wypisując `model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = resnet18(pretrained=True)\n",
    "model.fc = ???\n",
    "model.conv1 = ???\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    total_loss = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    progress = tqdm(enumerate(train_loader, 1), desc=\"Loss: \", total=len(train_loader))\n",
    "    \n",
    "    for i, data in progress:\n",
    "        X, y = data[0].to(device), data[1].to(device)\n",
    "        model.zero_grad()\n",
    "        outputs = model(X)\n",
    "        loss = loss_function(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        current_loss = loss.item()\n",
    "        total_loss += current_loss\n",
    "        \n",
    "        progress.set_description(\"Loss: {:.4f}\".format(total_loss/(i)))\n",
    "    \n",
    "    torch.save(model.state_dict(), 'resnet-mnist.pth')\n",
    "    \n",
    "    val_losses = 0\n",
    "    correct = 0\n",
    "    num_samples = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, data in tqdm(enumerate(val_loader, 1), total=len(val_loader)):\n",
    "            X, y = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(X)\n",
    "            val_losses += loss_function(outputs, y)\n",
    "            predicted_classes = torch.max(outputs, 1)[1]\n",
    "            correct += torch.sum(predicted_classes == y).cpu().numpy()\n",
    "            num_samples += len(y)\n",
    "\n",
    "    print(f'Validation Accuracy: {correct / num_samples * 100:.2f}%')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wczytanie zapisanej sieci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18(pretrained=False)\n",
    "model.fc = torch.nn.Linear(512, 10)\n",
    "model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "model.load_state_dict(torch.load('resnet-mnist.pth'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atak na Sieć Neuronową\n",
    "\n",
    "![zwodnicza panda](utils/fgsm_panda_image.png)\n",
    "\n",
    "Okazuje się, że sieci konwolucyjne można łatwo zmylić wprowadzając szum niewidoczny dla ludzkiego oka. Jedną z metod wprowadzenia takiego szumu jest policzenie gradientów funkcji likelihood po pikselach obrazu wejściowego dla nauczonej wcześniej sieci, a następnie dodanie do obrazka niewielkie, $\\epsilon$-owe zaburzenia zgodne ze znakiem gradientu.\n",
    "\n",
    "Mając więc obraz $x$, wybieramy dostatecznie małe $\\epsilon$ i obliczamy gradient funkcji kosztu $J$ dla ustalonych wag $\\theta$ przy danej etykiecie $y$, a następnie dodajemy jego znak do oryginalnego obrazu:\n",
    "\n",
    "$$\n",
    "    x + \\epsilon \\cdot \\operatorname{sign}(\\nabla_x J(\\theta, x, y)).\n",
    "$$\n",
    "\n",
    "**Zadanie 2.** Uzupełnić kod ataku w zaznaczonych miejscach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack(image, epsilon, data_grad):\n",
    "    # Pobranie dla każdego piksela znaku gradientu\n",
    "    sign_data_grad = ???\n",
    "    # Stworzenie zaburzonego obrazu zgodnie ze wzorem przy użyciu znaków gradientów\n",
    "    perturbed_image = ???\n",
    "    return perturbed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(dataset=val_data, batch_size=1, shuffle=True)\n",
    "num_tested = 500\n",
    "epsilons = [0, .001, 0.003, 0.005, 0.01, 0.1]\n",
    "\n",
    "model.eval()\n",
    "examples = []\n",
    "\n",
    "for epsilon in epsilons:\n",
    "    correct = 0\n",
    "    adv_examples = []\n",
    "\n",
    "    for i, test_data in tqdm(enumerate(test_loader, 1), total=num_tested):\n",
    "        data, target = test_data[0].to(device), test_data[1].to(device)\n",
    "\n",
    "        # Ustawienie obliczeń gradientu na obrazie wejściowym\n",
    "        ???\n",
    "\n",
    "        # Przejście w przód \n",
    "        output = model(data)\n",
    "        init_pred = output.max(1, keepdim=True)[1]\n",
    "\n",
    "        # Jeżeli sieć się pomyliła, niepotrzebny jest atak\n",
    "        if init_pred.item() != target.item():\n",
    "            continue\n",
    "\n",
    "        # Obliczenie funkcji kosztu (negative log likelihood)\n",
    "        loss = ???\n",
    "\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Zebranie gradientów z obrazu\n",
    "        data_grad = ???\n",
    "\n",
    "        # Wywołanie funkcji ataku FGSM\n",
    "        perturbed_data = ???\n",
    "\n",
    "        # Ponowna klasyfikacja zniekształconego obrazu\n",
    "        output = model(perturbed_data)\n",
    "\n",
    "        final_pred = output.max(1, keepdim=True)[1]\n",
    "        \n",
    "        if final_pred.item() == target.item():\n",
    "            correct += 1\n",
    "            if (epsilon == 0) and (len(adv_examples) < 5):\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "        else:\n",
    "            # Zapisanie obrazów na później\n",
    "            if len(adv_examples) < 5:\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "        \n",
    "        if i >= num_tested:\n",
    "            break\n",
    "\n",
    "    final_acc = correct/float(num_tested)\n",
    "    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, num_tested, final_acc))\n",
    "    \n",
    "    examples.append(adv_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "plt.figure(figsize=(8,10))\n",
    "for i in range(len(epsilons)):\n",
    "    for j in range(len(examples[i])):\n",
    "        cnt += 1\n",
    "        plt.subplot(len(epsilons),len(examples[0]),cnt)\n",
    "        plt.xticks([], [])\n",
    "        plt.yticks([], [])\n",
    "        if j == 0:\n",
    "            plt.ylabel(\"Eps: {}\".format(epsilons[i]), fontsize=14)\n",
    "        orig,adv,ex = examples[i][j]\n",
    "        plt.title(\"{} -> {}\".format(orig, adv))\n",
    "        plt.imshow(ex, cmap=\"gray\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
