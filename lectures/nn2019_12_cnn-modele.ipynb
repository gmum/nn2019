{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "<big><big><big><big><big><big>Sieci neuronowe 2018/19</big></big></big></big></big></big>\n",
    "\n",
    "---\n",
    "<big><big><big><big><big>Najważniejsze modele sieci konwolucyjnych</big></big></big></big></big>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "\n",
    "from bokeh.io import gridplot, output_file, show\n",
    "from bokeh.plotting import figure, output_notebook\n",
    "from bkcharts import Scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Typowy model\n",
    "<a href=\"https://cs.stanford.edu/people/karpathy/convnetjs/demo/cifar10.html\" target=\"_blank\">Demo typowego modelu CNN dla problemu CIFAR10 [Andrej Karpathy, Stanford]</a>\n",
    "\n",
    "Architektura\n",
    "  * input: 32 x 32 x 3\n",
    "  * konw : [+2] 5 x 5 --> 16, ReLU\n",
    "  * pool : 2 x 2 [+2]\n",
    "  * konw : [+2] 5 x 5 --> 20, ReLU\n",
    "  * pool : 2 x 2 [+2]\n",
    "  * konw : [+2] 5 x 5 --> 20, ReLU\n",
    "  * pool : 2 x 2 [+2]\n",
    "  * softm: 10 klas wyjściowych\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageNet: Alex net\n",
    "<img src=\"../nn_figures/imagenet.pdf\" width=\"80%\">[Krizhevsky, Sutskever, Hinton NIPS]\n",
    "1. Konkurs ILSVRC'2010 (ImageNet Large-Scale Visual Recognition Challenge)\n",
    "  * oryginalny zbiór danych ma ponad 22 miliony obrazów etykietowanych ponad 22 tysiącami klas\n",
    "  * zbiór danych konkursu to 1.2 miliona obrazów z 1000 różnych klas\n",
    "  * 50 tysięcy walidacyjnych, 150 tysięcy testowych\n",
    "  * obrazy różnych rozdzielczości przeskalowane i wycięte do $256\\times256$\n",
    "    * w końcowym uczeniu użyte obrazy $224\\times224$\n",
    "  * dwie miary błędów\n",
    "    * __top-1__ binarna miara prawidłowa/nieprawidłowa\n",
    "    * __top-5__ że prawidłowa etykieta __jest/nie jest__ wśród 5-ciu zaproponowanych\n",
    "  * problem uczony na danych __jedynie__ z odjętą średnią dla każdego piksela/kanału\n",
    "2. wyniki\n",
    "  * top-1 37.5\\% błędów\n",
    "  * top-5 17.0\\% błędów\n",
    "    * jedna z wersji osiągnęła 15.3\\% w top-5\n",
    "    * drugi najlepszy miał w top-5 26.2\\% błędów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architektura\n",
    "<img src=\"../nn_figures/imagenet.pdf\" width=\"80%\">[Krizhevsky, Sutskever, Hinton NIPS]\n",
    "1. 8 warstw: 5 konwolucyjnych i 3 warstwowe\n",
    "1. ostatnia warstwa jest softmaxem o wymiarze 1000 zwracającym szanse dla kazdej z klas\n",
    "2. kolejne warstwy konwolucyjne\n",
    "  * pierwsza $224\\times224\\times3$ ma 96 kerneli o wymiarach $11\\times11\\times3$ i stride $s=4$\n",
    "    * stąd wyjście to $55\\times55\\times96$\n",
    "    * a liczba parametrów to $11\\times11\\times3\\times96\\approx35K$\n",
    "    * niestety$\\ldots$ wielkość obrazu $224\\times224$ nie pasuje do kernela $11\\times11$\n",
    "      * $\\lfloor(224 - 11)/4\\rfloor+1=\\lfloor213/4\\rfloor+1=53+1=54\\ldots$\n",
    "      * obraz powinien być $227\\times227$\n",
    "      * nikt nie wie jak to zrobił Alex Krizhevsky\n",
    "  * druga na obrazie $55\\times55\\times48$ ma 256 kerneli $5\\times5\\times48$\n",
    "    * __uwaga__ warstwy konwolucyjne zostały zaimplementowane na dwóch GPU (Nvidia GTX-580 z 3GB pamięci każda)\n",
    "    * skutkuje to __podziałem__ kanałów na dwa procesory\n",
    "    * kernele w warstwie 3 biorą wejście z __wszystkich__ kerneli warstwy 2\n",
    "    * jednak kernele warstwy 4 biorą wejście __jedynie__ z kerneli na __tym samym__ GPU\n",
    "    * to powoduje zmianę głębokości\n",
    "    * ten schemat ulepszył wyniki po ok. 1.5\\% dla uzytych błędów\n",
    "  * trzecia warstwa konwolucji na __dwóch__ obrazach $27\\times27\\times128$ używa 384 kerneli $3\\times3\\times256$\n",
    "  * czwarta ma 384 kernele $3\\times3\\times192$ na obrazie $13\\times13\\times192$\n",
    "  * piąta ma 256 kerneli $3\\times3\\times192$ na obrazie $13\\times13\\times192$ dając dwa obrazy $13\\times13\\times128$\n",
    "3. warstwy max-pooling użyte są po pierwszej, po drugiej i po piątej konwolucji\n",
    "  * pooling $3\\times3$ ze stridem $2$\n",
    "  * wbrew zwyczajowi warstwy te są __nakładające__ się, co minimalnie zmniejsza wymiar\n",
    "  * po poolingu pierwszym i drugim jest warstwa _normalizacyjna_\n",
    "    * dość specyficzna normalizacja\n",
    "    * obecnie _nie używane_, bo nie daje żadnych dodatkowych efektów\n",
    "4. po piątej warstwie następują dwie warstwy po 4096 neuronów każda\n",
    "  * warstwy też podzielone pomiedzy dwa GPU\n",
    "5. na końcu $1000$ neuronów wyjściowych \n",
    "5. łącznie sieć ma ponad 60 milionów parametrów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ciekawe cechy\n",
    "1. pierwsze _znane_ użycie ReLU\n",
    "2. warstwy normalizacyjne już nie uzywane\n",
    "3. silna augmentacja\n",
    "4. dropout z $p=05$\n",
    "  * ale tylko w ostatnich warstwach fully connected\n",
    "  * dwukrotne wydłużenie czasu nauczania\n",
    "5. batch o wielkosci $128$\n",
    "6. uczenie SGD z momentum $0.9$\n",
    "7. $lr=0.01$ zmniejszane o rząd wielkości po wykryciu obszaru plateau (ręcznie)\n",
    "8. regularyzacja $L2$\n",
    "9. uzyskany błąd dla pojedynczej sieci wynosił $18.2\\%$ (błąd top-5)\n",
    "10. ensemble siedmiu sieci CNN zmniejszał go do $15.4\\%$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting\n",
    "1. w trakcie uczenia sieć overfitowała\n",
    "  * mimo ponad miliona przykładów\n",
    "2. augmentacja danych\n",
    "  * z oryginalnych $256\\times256$ wybrane losowo obrazy $224\\times224$\n",
    "  * także losowe poziome odbicia\n",
    "  * obrazy generowane na bieżąco\n",
    "  * 2048 razy więcej obrazów\n",
    "    * to oczywiście __nie__ oznacza 2048-krotnego zwiększenia informacji\n",
    "3. w trakcie testowania\n",
    "  * wybrane obrazy z rogów\n",
    "  * obraz centralny\n",
    "  * odbicia poziome każdego z nich\n",
    "  * uśrednione $10$ znalezionych predykcji\n",
    "4. modyfikacja intensywności kanałów RGB\n",
    "  * PCA na kanałach\n",
    "  * do każdego kanału dodana wielokrotność znalezionej składowej głównej przemnożonej przez warstość własną przez wartość losową z rokładu normalnego\n",
    "    * do każdego pksela $I_{xy}=[I_{xy}^R,I_{xy}^G,I_{xy}^B]$ dodana wartość $$[p_1,p_2,p_3][\\alpha_1\\lambda_1,\\alpha_2\\lambda_2,\\alpha_3\\lambda_3]^T$$ gdzie $p_i,\\lambda_i$ to $i$-te wektory i składowe główne macierzy kowariancji $x\\times3$ wartosci RGB\n",
    "  * ten schemat minimalizuje wpływ oświetlenia\n",
    "  * polepszył on wyniki top-1 o ponad 1\\%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nauczone filtry\n",
    "<img src=\"../nn_figures/imagenet-filters.pdf\" width=\"100%\">[Krizhevsky, Sutskever, Hinton NIPS'2012]\n",
    "1. model nauczył się szeregu różnych filtrów\n",
    "2. w warstwie pierwszej\n",
    "  * GPU1 nauczył się filtrów praktycznie nie zawierających kolorów, za to posiadających cechy wykrywające krawędzie i zwroty\n",
    "  * GPU2 wykrywał bloby kolorów\n",
    "  * według autorów następowało to zawsze __bez względu__ na inicjalizację\n",
    "3. filtry warstwy pierwszej przypominają filtry Gabora\n",
    "  * to w pewien sposób przypomina rozpoznawanie w warstwach V1 i V2 mózgu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obrazy\n",
    "<img src=\"../nn_figures/imagenet-images.pdf\" width=\"100%\">[Krizhevsky, Sutskever, Hinton NIPS]\n",
    "\n",
    "1. po lewej obrazy i ich klasyfikacje przez model\n",
    "2. po prawej obrazy testowe w pierwszej kolumnie i po pięć obrazów najbliższych w euklidesowej przestrzeni ostatniej warstwy ukrytej\n",
    "3. usunięcie którejkolwiek warstwy środkowej powodowało spadek skuteczności o ponad 2%\n",
    "  * głębokość gra rolę"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFAR-10 recognition [cs232n.stanford.edu](http://cs231n.stanford.edu)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZFNet\n",
    "1. w kolejnym ImageNet zwycięzcą była sieć ZFNet (Zeiler, Fergus)\n",
    "2. architektura oparta na AlexNet z modyfikacjami wynikającymi z doświadczeń\n",
    "  * konwolucje $11\\times11$, $stride=4$ w pierwszej warstwie zbyt drastycznie redukowały przestrzeń\n",
    "    * w ZFNet w pierwszej warstwie konwolucje $7\\times7$ ze $stride=2$\n",
    "  * liczba filtrów $384, 384, 256$ w warstwach $3, 4, 5$ była zbyt mała\n",
    "    * w ZFNet więcej filtrów $512, 1024, 512$\n",
    "3. błąd zredukowany do $14.8\\%$ (też yop-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG-16 (Simonyan, Zisserman, ImageNet'2014)\n",
    "<img src=\"../nn_figures/vgg16.png\" width=\"100%\"> [Simonyan, Zisserman, 2014]\n",
    "1. Krizhevsky et al. zwracali uwagę, że głębokość gra rolę\n",
    "2. jednocześnie wydawało się, że konwolucje muszą być duże na początku, by obejmować większy semantycznie obszar\n",
    "\n",
    "\n",
    "## Architektura\n",
    "3. jeśli jednak weźmiemy __mały__ wymiar kernela, to przy małym paddingu można utrzymać wymiar\n",
    "  * $k=3$, $p=\\lfloor3/2\\rfloor$ i wtedy $$o=i+2\\lfloor k/2\\rfloor-(k-1)=i+2\\left\\lfloor\\frac{2n+1}{2}\\right\\rfloor-(2n+1-1)=i+n-n=i$$\n",
    "  * to pozwala na dużą liczbę warstw\n",
    "4. kernel $3\\times3$ jest najmniejszym pozwalającym na wykrywanie krawędzi i pojęć lewy/prawy, góra/dół\n",
    "5. wejście stałe $224\\times224$ z odjętymi średnimi pikseli (jak w AlexNet)\n",
    "6. architektura na rysunku ma 16 warstw konwolucyjnych (wszystkie $3\\times3$) w blokach\n",
    "  1. $3\\times3\\times64$, ReLU, $3\\times3\\times64$, ReLU, max-pool\n",
    "  2. $3\\times3\\times128$, ReLU, $3\\times3\\times128$, ReLU, max-pool\n",
    "  3. $3\\times3\\times256$, ReLU, $3\\times3\\times256$, ReLU, $3\\times3\\times256$, ReLU,  max-pool\n",
    "  4. $3\\times3\\times256$, ReLU, $3\\times3\\times512$, ReLU, $3\\times3\\times512$, ReLU,  max-pool\n",
    "  5. $3\\times3\\times256$, ReLU, $3\\times3\\times512$, ReLU, $3\\times3\\times512$, ReLU,  max-pool\n",
    "  6. FC 4096, FC 4096, FC 1000, softmax\n",
    "7. rozszerzona sieć z 19 warstwami\n",
    "  1. $3\\times3\\times64$, ReLU, $3\\times3\\times64$, ReLU, max-pool\n",
    "  2. $3\\times3\\times128$, ReLU, $3\\times3\\times128$, ReLU, max-pool\n",
    "  3. $3\\times3\\times256$, ReLU, $3\\times3\\times256$, ReLU, $3\\times3\\times256$, ReLU,  max-pool\n",
    "  4. $3\\times3\\times256$, ReLU, $3\\times3\\times512$, ReLU, $3\\times3\\times512$, ReLU, $3\\times3\\times512$, ReLU,  max-pool\n",
    "  5. $3\\times3\\times256$, ReLU, $3\\times3\\times512$, ReLU, $3\\times3\\times512$, ReLU, $3\\times3\\times512$, ReLU, max-pool\n",
    "  6. FC 4096, FC 4096, FC 1000, softmax\n",
    "7. w jeszcze innej konfiguracji z 16 warstwami ostatnie konwolucje w dwóch ostatnich blokach (4. i 5.) były o wymiarach $1\\times1$\n",
    "  * konwolucje $1\\times1$ w zasadzie nie wykorzystują/wprowadzają żadnej informacji o sąsiedztwie\n",
    "  * jednak zwiększają nieliniowość __nie__ zmieniając wymiaru\n",
    "8. Ale...\n",
    "  * ten model (podobnie jak GoogleNet) był stworzony tuż przed powstaniem BatchNormalization\n",
    "  * autorzy uczyli \"sprytnie\"\n",
    "    * najpierw nauczyli model z 11-warstwami\n",
    "    * potem dodawali pojedyncze warstwy pośrodku\n",
    "  * podobnie GoogleNet dodał pośrednie funkcje kosztu\n",
    "  \n",
    "## Uczenie\n",
    "1. sieć ma większą liczbę parametrów niż AlexNet \n",
    "  * ok. 140 milionów\n",
    "  * większość pamięci jest przy przetwarzaniu w dwóch pierwszych warstwach konwolucyjnych\n",
    "    * w pierwszej $224\\times224\\times64\\approx3.2M$\n",
    "    * ale parametrów w pierwszej tylko $3\\times3\\times3\\times64=1728$\n",
    "  * większość parametrów w ostatnch warstwach FC\n",
    "    * razem $7\\times7\\times512\\times4096+4096\\times4096+4096\\times1000\\approx123.5M$\n",
    "    * okazuje się, że zamiast tylu warstw FC _lepiej_ jest użyć _average pooling_ w ostatniej warstwie konwolucyjnych\n",
    "      * ostatnia warstwa konwolucyjna daje blok $7\\times7\\times512$\n",
    "      * można uzyskać warstwę $512$ liczb przez _uśrednienie_ po poziomicy $7\\times7$ liczb\n",
    "      * i pozbyć się warstw FC co działa względnie dobrze!\n",
    "2. uczenie SGD z momentum rozpoczęło się ze współczynnikiem uczenia $0.01$ by być zmniejszonym gdy spadek na zbiorze walidacyjnym zanikł\n",
    "3. uczenie zostało zatrzymane po 370 tysiącach iteracji\n",
    "4. model był uczony na dwóch rozdzielczościach: 256 i 384 pikseli\n",
    "\n",
    "## Wyniki\n",
    "1. wersje 16- i 19-warstwowe osiągały do 24.8% w top-1 i 7.5% w top-5\n",
    "2. wersja złożona z 2 modeli osiągała 23.7% oraz 6.8% (7.32% w złożonym modelu)\n",
    "3. to wyniki porównywalne ze zwycięzcą GoogleNet, który miał 6.67%\n",
    "4. a model vgg-16 jest znacznie prostszy..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GoogleNet (Szegedy et al.)\n",
    "<img src=\"../nn_figures/inception-naive.pdf\" width=\"50%\"><img src=\"../nn_figures/inception-reduction.pdf\" width=\"50%\">[Szegedy et al. 2015]\n",
    "1. ten model rozwinął głębokość\n",
    "2. cały model zbudowany jest z modułów __inception__\n",
    "  * konwolucje mają wymiary $5\\times5$, $3\\times3$ i $1\\times1$\n",
    "  * wymiary podyktowane wygodą, by łatwiej się zgadzały granice\n",
    "  * każdy moduł jest połączeniem wielu konwolucji wraz z poolingiem\n",
    "    * ekstrakcja cech na wielu poziomach jednocześnie\n",
    "    * $1\\times1$ pozwala na konwolucje nie przestrzenną (spatial), ale tzw. __cross-channel__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naiwny blok inception\n",
    "<img src=\"../nn_figures/inception-naive.pdf\" width=\"50%\">\n",
    "\n",
    "* konwolucje mają wymiary $5\\times5$, $3\\times3$ i $1\\times1$\n",
    "* jakie są wymiary\n",
    "* niech wejście będzie $28\\times28\\times256$\n",
    "  * konwolucje $1\\times1$ dają wyjście $28\\times28\\times128$ ($128$ to liczba kanałów)\n",
    "  * konwolucje $3\\times3$ (ze stride $1$ i padding $1$) dają $28\\times28\\times192$\n",
    "  * konwolucje $5\\times5$ (ze stride $1$ i padding $2$) dają $28\\times28\\times96$\n",
    "  * pooling $3\\times3$ daje $28\\times28\\times256$ \n",
    "    * pooling nie redukuje głębokości i ta zawsze tylko rośnieb\n",
    "* wszystkie wyniki są konkatenowane _w głąb_\n",
    "  * to daje razem $28\\times28\\times(128+192+96+256)=672$!\n",
    "* w efekcie bardzo złożone obliczeniowo\n",
    "  * $1\\times1$ wymagają $28\\times28\\times128\\times1\\times1\\times256$\n",
    "  * $3\\times3$ wymagają $28\\times28\\times192\\times3\\times3\\times256$\n",
    "  * $5\\times5$ wymagają $28\\times28\\times96\\times5\\times5\\times256$\n",
    "  * razem __ponad__ $850$ milionów operacji dla jednego bloku inception\n",
    "* problemem jest bardzo duża głębokość"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rozszerzony blok inception\n",
    "<img src=\"../nn_figures/inception-reduction.pdf\" width=\"50%\">\n",
    "\n",
    "* wykorzystanie modułów bottleneck przez konwolucje $1\\times1$\n",
    "* konwolucje bottleneck $1\\times1$ redukują głębokość do $64$ filtrów dając $28\\times28\\times64$\n",
    "  * zarówno te po warstwie poprzedniej, jak i ta po pooling\n",
    "* w ten sposób mamy\n",
    "  * $1\\times1$ dają wyjście $28\\times28\\times128$ ($128$ to liczba kanałów)\n",
    "  * bottleneck $1\\times1$ dają wyjście $28\\times28\\times64$\n",
    "  * $3\\times3$ (ze stride $1$ i padding $1$) dają $28\\times28\\times192$\n",
    "  * bottleneck $1\\times1$ dają wyjście $28\\times28\\times64$  \n",
    "  * $5\\times5$ (ze stride $1$ i padding $2$) dają $28\\times28\\times96$\n",
    "  * pooling $3\\times3$ daje $28\\times28\\times256$ \n",
    "  * bottleneck $1\\times1$ dają wyjście $28\\times28\\times64$\n",
    "* i na wyjściu tylko 480 filtrów\n",
    "* a ile operacji?\n",
    "  * bottleneck  $1\\times1$ potrzebują $28\\times28\\times64\\times1\\times1\\times256$\n",
    "  * bottleneck  $1\\times1$ potrzebują $28\\times28\\times64\\times1\\times1\\times256$\n",
    "  * $1\\times1$ wymagają $28\\times28\\times128\\times1\\times1\\times256$\n",
    "  * $3\\times3$ wymagają $28\\times28\\times192\\times3\\times3\\times64$\n",
    "  * $5\\times5$ wymagają $28\\times28\\times96\\times5\\times5\\times64$\n",
    "  * bottleneck  $1\\times1$ potrzebują $28\\times28\\times64\\times1\\times1\\times256$\n",
    "  * razem tylko ok. $360$ milionów operacji\n",
    "* wykorzystanie bottleneck pozwala także redukować głębokość kolejnych warstw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. dla zapewnienia inwariantności na translacje używamy powtarzalnych bloków\n",
    "  * blok ma analizować korelacje w warstwie i grupować je z dużą korelacją\n",
    "  * te tworzą elementy kolejnej warstwy\n",
    "  * klastry skoncentrowane w jednym regionie mogą być łatwo przetwarzane przez konwolucje $1\\times1$ dla zwiększenia nieliniowości\n",
    "  * bardziej rozległe cechy muszą być pokryte przez kernele o większym wymiarze\n",
    "  * dodatkowy pooling też daje zyski\n",
    "  * tak wygląda _naiwny_ moduł inception\n",
    "4. poważnym problemem tak poustawianych jeden na drugim modułów będzie coraz większe rozrzucenie przestrzenne cech wyższego rzędu\n",
    "  * to sugeruje zwiększenie frakcji udziału konwolucji $3\\times3$ i $5\\times5$ na wyższych poziomach\n",
    "  * a to staje się coraz bardziej kosztowne na wyższych poziomach\n",
    "  * łączenie wyjścia poolingu oraz konwolucji spowoduje zwiększenie liczby wyjść z każdym krokiem, co będzie nieefektywne\n",
    "6. moduły inception są ustawiane jeden po drugim\n",
    "  * to pozwala na zwiększanie ich liczby __bez__ niekontrolowanego wzrostu złożoności"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GoogLeNet\n",
    "\n",
    "<img align=\"right\" src=\"../nn_figures/googlenet.pdf\" width=\"70%\">\n",
    "\n",
    "1. sieć jest bardzo głęboka\n",
    "  * propagacja gradientów wgłąb może być problemem\n",
    "  * aby cały model dawał dobre wyniki, cechy generowane na niższych i środkowych warstwach powinny być dyskryminatywne\n",
    "2. GoogLeNet dodaje klasyfikatory na niższych i środkowych poziomach\n",
    "  * proste moduły average pool --> $1\\times1$ konwolucje --> FC --> FC --> softmax\n",
    "    * softmax ma tyle wyjść ile oryginalny model na końcu\n",
    "  * powinny wzmacniać poprawne klasyfikacje na tych poziomach\n",
    "  * zwiększać sygnał gradientu\n",
    "    * przeciwdziałanie zanikaniu\n",
    "    * dodawać regularyzację\n",
    "    * w ogóle umożliwić uczenie w erze bez batchNormalization\n",
    "3. te klasyfikatory\n",
    "  * są dodane w środkowych modułach 4a i 4d\n",
    "  * mają postać małych sieci konwolucyjnych\n",
    "  * ich koszt jest dodawany do całkowitego zdyskontowane (zwykle ich koszty przemnożone przez 0.3)\n",
    "  * usunięte w trakcie inferencji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Liczba parametrów\n",
    "1. AlexNet miał ok. 60 milionów\n",
    "2. VGG19 osiągnął w ILSVR'2014 wynik minimalnie słabszy od GoogLeNet\n",
    "3. VGG19 ma zaletę bardzo __prostej__ architektury ale kosztem olbrzymiej liczby parametrów - ok. 180 milionów\n",
    "4. GoogLeNet ma tylko 5 milionów parametrów\n",
    "  * powinna być lepsza generalizacja\n",
    "  * mniej dodatkowych chwytów (augmentacja, itp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dekonwolucje\n",
    "1. dekonwolucje są w rzeczywistości transponowanymi konwolucjami\n",
    "2. pozwalają odwrócić cykl\n",
    "  * cześć konwolucyjna od obrazu do reprezentacji\n",
    "  * część odwracająca reprezentację do postaci obrazu\n",
    "  \n",
    "<img src=\"../nn_figures/101-inp.jpg\" width=\"45%\"><img src=\"../nn_figures/101-out.jpg\" width=\"45%\">\n",
    "<img src=\"../nn_figures/699-inp.jpg\" width=\"45%\"><img src=\"../\n",
    "nn_figures/699-out.jpg\" width=\"45%\"> [za P. Garg]\n",
    "  * konwolucyjna\n",
    "    * Conv2d(16, 4) -> ReLU -> MaxPool(2) -> Conv2d(32, 5) -> ReLU -> MaxPool(2) -> Conv2d(64, 3) -> ReLU\n",
    "  * dekonwolucyjna \n",
    "    * ConvTransp2d(32, 3) -> ReLU -> MaxUnPool(2) -> ConvTransp2d(16, 5) -> ReLU -> MaxUnPool(2) -> ConvTransp2d(3, 4) -> ReLU\n",
    "3. pozwala na odszumianie oraz semantyczną segmentację\n",
    "4. max-pool __nie jest__ operacją odwracalną\n",
    "  * jak zrobić un-pooling?\n",
    "    * zapamiętując indeksy\n",
    "      * każdy max-pool zapamietuje __która__ z pozycji w kernelu (np. 2x2) miała najwyższą wartość\n",
    "      * przy odwracaniu ta pozycja dostaje wartość wyjściową, a pozostałe 0\n",
    "    * a jeśli indeksy __nie są__ dostępne?\n",
    "      * niech architektura będzie architekturą autoenkodera\n",
    "      * od wejścia do warstwy latent $Z$ jest sieć konwolucyjna\n",
    "      * od latent do wyjściowej dekonwolucyjna\n",
    "      * zadaniem jest __wylosować__ $z\\in{}Z$ co nie podaje indeksów\n",
    "      * najprostszym rozwiązaniem jest __upsampling__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network in Network\n",
    "1. filtr konwolucji jest w rzeczywistości uogólnionym modelem liniowym (GLM)\n",
    "  * poziom abstrakcji nie jest wysoki\n",
    "  * konieczne jest tworzenie wielu filtrów\n",
    "  * problem gdy dane dla pewnego wzorca (concept) leżą na bardziej skomlikowanej powierzchni niż półpłaszczyna\n",
    "2. warstwa __mlpconv__ wykorzystuje nieliniowy detektor\n",
    "<img src=\"../nn_figures/nin.pdf\" width=\"80%\">\n",
    "\n",
    "  * filtr konwolucyjny wraz z nieliniową aktywacją, np. ReLU, oblicza $$f_{ijk}\\max(w_K^Tx_{ij},0)$$\n",
    "    * naturalnie obliczana jest liczba warstw zgodna z definicją MLP - może być głęboką siecią\n",
    "  * podobnie mlpconv mapuje pewien obszar (patch) do wartości wyjsciowej w następnej warstwie\n",
    "  * dzieje się tak przez wielowarstwowy perceptron z nielioniowymi aktywacjami\n",
    "  * MLP jest __wspólny__ dla wszystkich lokalnych pól wejściowych\n",
    "  * średnia ostatniej warstwy jest przekazywana jako wartość zaufania do obliczonych cech\n",
    "  * to przypomina $maxout$ gdzie wybierane jest maksimum z wielu obliczonych wartości"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konwolucje $1\\times1$\n",
    "1. nikt nam nie zabrania ustalenia wymiaru kernela na $k=1$, ale po co...?\n",
    "2. konwolucja $1\\times1$ oblicza __nieliniową__ funkcję na pojedynczej kolumnie pikseli obrazu\n",
    "  * to może być moduł typu NiN\n",
    "3. pozwala na efektywną redukcję wymiarowości, tzn. liczby kanałów\n",
    "  1. 256 kanałów -- konwolucje 1x1 --> 64 kanały -- konwolucje 4x4 --> 256 kanałów\n",
    "  2. 256 kanałów -- konwolucje 4x4 --> 256 kanałów\n",
    "  * które rozwiązanie jest szybsze???\n",
    "4. konwolucje przestrzenne na kanałach przetworzonych wcześniej przez $1\\times1$ odpowiadają konwolucją na przestrzeniach osadzonych (__embedding__)\n",
    "  * takie konwolucje są bardzo wydajne nie tracąc informacji\n",
    "  * przetwarzania na embeddingach są bardzo popularne np. w NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Densenet\n",
    "<img src=\"../nn_figures/denseblock.pdf\" width=\"80%\"> [Huang, Liu, Weinberger, Maaten 2017]\n",
    "1. wyjście z każdej warstwy (lub ich grupy) jest podłączone do __wszystkich późniejszych__ warstw\n",
    "  * połączenie jako \n",
    "    * konkatenacja wszystkich poprzednich warstw\n",
    "    * batch normalization\n",
    "    * ReLU\n",
    "    * konwolucja $3\\times3$\n",
    "2. ponieważ konkatenacja nie byłaby możliwa przy zmianie rozmiarów map warstwy są poddawana poolingowi w warstwach dostosowujących\n",
    "  * batch normalization\n",
    "  * konwolucje $1\\times1$\n",
    "  * $2\\times2$ average pooling\n",
    "3. przed konwolucjami $3\\times3$ dodawane są konwolucje $1\\times1$ dla zmniejszenia wymiarowości i poprawie efektywności\n",
    "<img src=\"../nn_figures/densenet.png\" width=\"100%\"> [Huang, Liu, Weinberger, Maaten]\n",
    "4. DenseNet z różnymi parametrami (wielkościami warstw, ich głębokościami, etc) osiągał (wg. metodologii takiej jak w AlexNet) na zbiorze ILSVRC'2012\n",
    "  * top-1: 23.6%, 22.1%, 21.5%, 20.8%\n",
    "  * top-5: 6.66%, 5.92%, 5.44%, 5.29%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Squeezenet\n",
    "<img src=\"../nn_figures/squeezenet.png\" width=\"100%\"> [Indola, Han, Moskewicz, Ashraf, Dally, Keutzer]\n",
    "1. celem autorów było __zmniejszenie__ sieci CNN\n",
    "  * łatwiej jest uczyć małe modele w równoległym środowisku\n",
    "  * prostsza aktualizacja nauczonych modeli, np. automatyczna przez Internet\n",
    "  * możliwość implementacji na FPGA\n",
    "2. próba rozwiązania w Squeezenet wykorzystując\n",
    "  * zamiana dużej liczby konwolucji $3\\times3$ na konwolucje $1\\times1$\n",
    "  * zmniejszenie liczby kanałów wejściowych dla konwolucji $3\\times3$\n",
    "    * przez wykorzystanie warstw __squeeze__\n",
    "  * downsampling (pooling) __późno__ w architekturze, by konwolucje miały większe mapy aktywacji, co prowadzi do niższych błędów\n",
    "3. moduł __fire__\n",
    "<img src=\"../nn_figures/squeezenet-fire.pdf\" width=\"60%\"> [Indola, Han, Moskewicz, Ashraf, Dally, Keutzer]\n",
    "  * moduł zgniatający z konwolucji $1\\times1$\n",
    "  * przekazujący wyjście do konwolucji $1\\times1$ i $3\\times3$\n",
    "  * pozwala na zmniejszenie liczby kanałów wejsciowych do konwolucji $3\\times3$\n",
    "4. końcowa warstwa __nie ma__ pełnych połączeń, a tylko _average pooling_ jak w NiN\n",
    "5. metoda kompresji sieci zastosowana do\n",
    "  * AlexNet\n",
    "    * SVD zmniejsza sieć 5-krotnie i top-1 do 56%\n",
    "    * Network Pruning 9-krotnie, top-1 do 57.2%, top-5 do 29.8%\n",
    "    * Deep Compression zmniejsza AlexNet 35-krotnie bez zmiany poziomu błędu\n",
    "  * SqueezeNet osiąga 50-krotną redukcję względem AlexNet __bez zmiany__ poziomów błędu\n",
    "    * Deep Compression z 6-bitową kwantyzacją i 33% rzadkością daje model o wielkości ok. 0.47MB\n",
    "      * ponad 500 razy mniejszy niż AlexNet!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
