{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "<big><big><big><big><big><big>Sieci neuronowe 2018/19</big></big></big></big></big></big>\n",
    "\n",
    "---\n",
    "<big><big><big><big><big>Mechanizmy atencji Memory Network</big></big></big></big></big>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "\n",
    "from bokeh.io import gridplot, output_file, show\n",
    "from bokeh.plotting import figure, output_notebook\n",
    "from bkcharts import Scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image inclusion\n",
    "<img src=\"../nn_figures/\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory Networks\n",
    "MN składają się z pamięci $M$ oraz czterech funkcji\n",
    "* $I$ (input feature map) konwertującej wejście na wewnętrzną reprezentację $I(x)$\n",
    "  * dowolna konwersja czytelnego wejścia na cechy \n",
    "* $G$ (generalisation) modyfikującej pamięć $m_i=G(m_i, I(x))$\n",
    "  * generalizacja, bo może poprawiać pamięć\n",
    "  * najprostsze $G$ zapamiętuje informację w komórce $$m_{H(x)}=I(x)$$ bez modyfikacji innych\n",
    "  * może być bardzo kosztowne przy dużej pamięci\n",
    "    * w oryginalnej pracy pamięć miała 14 milionów komórek\n",
    "    * możliwe _haszowanie_ słów w zdaniu i wstawianie do kubełka\n",
    "* $O$ (output feature map) mapuje wejście i pamięć na nową reprezentację cech wyjścia $o=O(I(x), m)$\n",
    "  * typowo przy odtwarzaniu odszukuje w pamięci $k$ komórek najbardziej pasujących\n",
    "    * zwraca zdania porangowane\n",
    "  * przy haszowaniu porównuje tylko zdania z komórek pasujących\n",
    "* $R$ (response) generuje nowe wyjście z utworzonej reprezentacji $r=R(o)$\n",
    "  * tworzy odpowiedź na podstawie zdania o najwyższej randze\n",
    "  * gdy więcej zdań, można wykorzystać RNN dla konstrukcji odpowiedzi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MN naiwny model podstawowy\n",
    "$I, G, O, R$ muszą być nauczone: jeśli modelami dla nich są sieci neuronowe, to autorzy nazywają to __MemNN__\n",
    "\n",
    "<img src=\"../nn_figures/MN.png\" width=\"80%\">\n",
    "\n",
    "1. $I$ przetwarza tekst albo przez identyczność, albo ustalony embedding\n",
    "2. $G$ zapamiętuje $I(x)$ w _następnej_ wolnej komórce\n",
    "  * w wersji bardziej zaawansowanej możliwe będzie poprawianie\n",
    "3. $O$ wyszukuje $k$ komórek z zawartością najbardziej spójną z pytaniem $$o_1=\\arg\\max_is_O(I(x), m_i)$$ gdzie $s_O$ jest odpowiednią funkcją \n",
    "  * w wersji podstawowej $k=2$\n",
    "  * drugim będzie $$o_2=\\arg\\max_is_O([I(x),m_{o_1}], m_i)$$\n",
    "4. $R$ zwraca czytelną odpowiedź\n",
    "  * w najprostszej postaci to $m_{o_k}$\n",
    "  * zwykle $R$ będzie rangować słowa ze znalezionych zdań $$r=\\arg\\max_ws_R([x,m_{o_1},m_{o_2}],w)$$\n",
    "  \n",
    "Tworzenie odpowiedzi wymaga __rozumienia__ słów ze słownika.\n",
    "\n",
    ">> \n",
    "Joe went to the kitchen. Fred went to the kitchen. Joe picked up the milk.\n",
    "Joe travelled to the office. Joe left the milk. Joe went to the bathroom.\n",
    "* Where is the milk now? \n",
    "  * office\n",
    "* Where is Joe? \n",
    "  * bathroom\n",
    "* Where was Joe before the office?\n",
    "  * kitchen\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MN uczenie\n",
    "* uczenie jest w pełni nadzorowane\n",
    "  * podawane pełne zdania i najlepsze odpowiedzi\n",
    "* model wymaga dobrego nauczenia się funkcji $s_O$ i $s_R$\n",
    "* cały model uzony SGD\n",
    "  * sampling zdań"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MN rozszerzenia\n",
    "\n",
    "### strumień słów\n",
    "* słowa mogą przychodzić _nie_ jako pełne zdania, ale w strumieniu\n",
    "* konieczny _dodatkowy_ model, który odkrywa fragmenty\n",
    "* po znalezieniu każdego fragmentu MN traktuje ostatni jak zdanie\n",
    "\n",
    "### efektywne wykorzystanie pamięci\n",
    "* duża pamięć powoduje dużą złożoność $O$\n",
    "* __kubełkowanie__\n",
    "  * każde zdanie jest haszowane do kilku kubełków\n",
    "  * $O$ porównuje zdanie jedynie z kubełka wyliczonego dla zapytanie\n",
    "    * haszowanie na poziomie słów\n",
    "      * tylko zdania dzielące słowa będą sprawdzane\n",
    "    * klastrowanie embeddingów słów\n",
    "      * embeddingi pozwalają na sprawdzanie także synonimów\n",
    "\n",
    "### relacja w czasie\n",
    "* wykorzystanie $\\Phi(x,y,y')$ określającą relację w czasie\n",
    "* ułatwia wyszukiwanie odpowiedzi\n",
    "\n",
    "### modelowanie nie widzianych słów\n",
    "* czasem pojawiają się nazwy własne i inne słowa widziane po raz pierwszy\n",
    "* model językowy wykorzystujący lewy i prawy kontekst rozpoznaje czym nowe słowo powinno być\n",
    "  * dla każdego słowa pamiętany zbiór jego lewych i prawych kontekstów\n",
    "  * w trakcie uczenia algorytm losowo \"udaje\", że słowa nie widział wcześniej douczając się\n",
    "  \n",
    "### wiedza o świecie\n",
    "* poza zdaniami o konkretnej sytuacji model może otrzymywać ogólną wiedzę o świecie\n",
    "\n",
    ">>\n",
    "* Fred went to the kitchen. Fred picked up the milk. Fred travelled to the office.\n",
    "* Where is the milk ?\n",
    "  * office\n",
    "* Where does milk come from ? \n",
    "  * milk come from cow\n",
    "* What is a cow a type of ? \n",
    "  * cow be female of cattle\n",
    "* Where are cattle found ? \n",
    "  * cattle farm become widespread in brazil\n",
    "* What does milk taste like ? \n",
    "  * milk taste like milk\n",
    "* What does milk go well with ?\n",
    "  * milk go with coffee\n",
    "* Where was Fred before the office ? \n",
    "  * kitchen\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
