{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "<big><big><big><big><big><big>Sieci neuronowe 2018/19</big></big></big></big></big></big>\n",
    "\n",
    "---\n",
    "<big><big><big><big><big>Głębokie sieci warstwowe i regularyzacja</big></big></big></big></big>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "\n",
    "#from bokeh.io import gridplot, output_file, show\n",
    "#from bokeh.plotting import figure, output_notebook\n",
    "#from bkcharts import Scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Głębokie sieci\n",
    "> __Ogólne twierdzenie o aproksymacji__ mówi, że sieć warstwowa, z liniowymi neuronami ukrytymi oraz jedną warstwą ukrytą ze _zgniatającą_ funkcją aktywacji (np. logistyczną) jest w stanie aproksymować z dowolną dokładnością dowolną mierzalną funkcję ciągłą na domknietym podzbiorze $\\mathbb{R}^n$ pod warunkiem, że sieć będzie miała __wystarczającą__ liczbe neuronów ukrytych.\n",
    "\n",
    "* liczba neuronów ukrytych jest zwykle wykładniczo duża\n",
    "* sieć będzie potrafiła __aproksymować__ funkcję, ale nie ma żadnej gwarancji, że się jej __nauczy__\n",
    "* ale istnieje rodzina funkcji, które mogą być przedstawione pod warunkiem odpowiedniej __głębokości__\n",
    "* empirycznie wiemy, że większa głębokość daje zwykle lepszą generalizację"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularyzacja\n",
    "Celem regularyzacji jest osiągniecie modelu o niższej złożoności.\n",
    "* zwykle celem jest minimalizacja __wariancji__ kosztem nieco zwiększonego __biasu__\n",
    "* reguła Ockhama\n",
    "  * jest bardziej prawdopodobne, że model prostszy jest prawdziwy, niż model bardziej złożony\n",
    "    * spośród dwóch modeli tłumaczących równie dobrze jakieś zjawisko wybrać ten prostszy\n",
    "  * optymalizacja parametrów $\\theta$\n",
    "  $$\\begin{align}\n",
    "  \\theta^\\ast&=\\underset{\\theta}{\\arg\\max}P(D\\mid\\theta)P(\\theta)=\\underset{\\theta}{\\arg\\max}\\log\\,P(D\\mid\\theta)P(\\theta)\\\\\n",
    "  &=\\underset{\\theta}{\\arg\\max}[\\log\\,P(D\\mid\\theta)+\\log\\,P(\\theta)]\\\\\n",
    "  &=\\underset{\\theta}{\\arg\\min}[-\\log\\,P(D\\mid\\theta)-\\log\\,P(\\theta)]\n",
    "  \\end{align}$$\n",
    "    * czynnik $-\\log\\,P(\\theta)$ odpowiada złożoności zestawu parametrów\n",
    "    * to reguła Minimum Description Length: najlepszą hipotezą dla z\n",
    "  * jest wiele poglądów, że powoływanie się na regułę Ockhama jest fałszywe\n",
    "\n",
    "## Regularyzacja przez czynnik kary\n",
    "$$L(w; X, y)=L(w; X, y)+\\alpha\\Omega(w)$$\n",
    "* algorytm uczący bedzie minimalizował koszt na danych\n",
    "* oraz jakąś miarę na parametrach $w$\n",
    "  * __nie__ regularyzujemy biasów\n",
    "  * wagi kontrolują interakcję między dwoma neuronami\n",
    "  * biasy tylko jednego neuronu\n",
    "  * biasy wprowadzają mniej wariancji w modelu\n",
    "* może się okazać potrzebne __oddzielne__ regularyzowanie różnych warstw\n",
    "  * różne $\\alpha$ dla róznych warstw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $L2$\n",
    "$$\\Omega(w)=\\frac{1}{2}\\|w\\|_2^2$$\n",
    "* ridge regression albo regresja Tikhonova\n",
    "$$\\begin{align}\n",
    "w&=w-\\epsilon(\\alpha{}w+\\nabla_wL(w))\\\\\n",
    "&=(1-\\epsilon\\alpha)w-\\epsilon\\nabla_wL(w)\n",
    "\\end{align}$$\n",
    "\n",
    "Regularyzacja L2 powoduje __skalowanie__ optymalnego wektora wag $w^*$ __wzdłuż__ wektorów głównych zdefiniowanych przez macierz Hesjanu $H$\n",
    "<img src=\"../nn_figures/L2.pdf\" width=\"80%\"> [Goodfellow et al.]\n",
    "1. wektor $w^*$ jest przeskalowany wzdłuż $i$-tego wektora głównego $H$ przez czynnik $\\dfrac{\\lambda_i}{\\lambda_i+\\alpha}$, gdzie $\\alpha$ jest czynnikiem  funkcji kary\n",
    "  * jeśli $\\lambda_i>>\\alpha$, to regularyzacja będzie niewielka\n",
    "  * jeśli $\\lambda_i<<\\alpha$, to współrzędna będzie zredukowana prawie do minimum\n",
    "2. na rysunku\n",
    "  * $\\tilde{\\ w}$ jest punktem ekwilibrium miedzy minimum kosztu, a regularyzacją\n",
    "  * w pierwszym głównym kierunku wzdłuż $w_1$ wartość własna $H$ jest niewielka\n",
    "    * funkcja kosztu nie zmienia się wiele w tym kierunku, a wobec tego regularyzator ma duży wpływ i skraca $w_1$ do zera\n",
    "  * w drugim kierunku funkcja celu jest bardzo czula na zmiany\n",
    "    * wartość własna jest wysoka\n",
    "    * regularyzator mało wpływa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $L1$\n",
    "Składnik kosztu jako $$\\Omega(w)=\\|w\\|_1=\\sum_i\\mid w_i\\mid$$\n",
    "* tylko wagi, nie bias\n",
    "* gradient $$\\nabla_wL(w)=\\nabla_wL(w)+\\alpha{}sign(w)$$\n",
    "* zachowanie jest inne niż $L2$\n",
    "  * gradient nie skaluje się liniowo z każdym $w$, stąd brak czystych rozwiązań\n",
    "  * rozwinięcie funkcji kosztu wraz z poprawką $L1$ \n",
    "  $$L(w)=L(w+(w-w^*))=L(w)+\\sum_i\\left[\\frac{1}{2}H(w-w^*)+\\alpha\\mid{}w_i\\mid\\right]$$\n",
    "    * skladnik pierwszej pochodnej znika, bo $w^*$ jest optimum\n",
    "  * rozwiązanie analityczne ma postać\n",
    "  $$w_i=sign(w_i^*)\\,\\max\\left[\\mid{}w_i^*\\mid-\\frac{\\alpha}{H_{i,i}},\\,0\\right]$$\n",
    "  zakładając, że $H$ jest diagonalna\n",
    "    * jeśli $\\mid{}w_i^*\\mid\\leq\\frac{\\alpha}{H_{i,i}}$\n",
    "      * tu rozwiązaniem jest $w_i=0$\n",
    "      * regularyzacja przeważa\n",
    "    * jeśli $\\mid{}w_i^*\\mid>\\frac{\\alpha}{H_{i,i}}$\n",
    "      * $w_i$ jest przesuwane\n",
    "* $L1$ daje bardziej __rzadkie__ rozwiązanie\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rozszerzanie zbioru uczącego\n",
    "1. na pewno lepiej jest mieć więcej danych niż mniej\n",
    "2. sztuczne dane\n",
    "  * klasyfikator powinien być inwariantny na transformacje - wystarczy je zastosować\n",
    "  * ale ostrożnie gdy mogą one zmienić znaczenie: 6 a 9\n",
    "3. szum losowy\n",
    "  * także dodawany do neuronów ukrytych\n",
    "  * sieci bywają mało odporne na szum\n",
    "  * wykorzystywane w tzw. __denoising autoencoders__\n",
    "  * także __dropout__ jest formą dodawania szumu (właściwie __mnożenia__ przez szum)\n",
    "4. ostrożność przy porównywaniu algorytmów\n",
    "  * jeden algorytm działa słabo przy danych czystych\n",
    "  * drugi dobrze przy danych rozszerzonych\n",
    "  * jaki można wyciągnąć wniosek?\n",
    "  * ale pamiętac by warunki porównania były sprawiedliwe (ten sam zbiór dla porównań)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dodawanie szumu do neuronów wyjsciowych\n",
    "* zbiory mają błędy w etykietach\n",
    "* maksymalizacja $\\log\\,p(y\\mid x)$ może zaszkodzić, jesli etykieta $y$ jest błędna\n",
    "* jak temu zaradzić?\n",
    "  * modelować szum etykietowań\n",
    "  * załóżmy, że etykiety są poprawne z prawdopodobieństwem $1-\\epsilon$\n",
    "  * najlepiej __dodać__ to założenie do funkcji kosztu\n",
    "  * __label smoothing__\n",
    "    * zastąpienie w modelu opartym o _softmax_ etykiet $0$ i $1$ przez $\\frac{\\epsilon}{k}$ i $1-\\frac{k-\\epsilon}{k}$\n",
    "    * uczenie nigdy nie dotrze do etykiet $0$ i $1$\n",
    "    * będzie się długo uczyć ciągle __powiekszając__ wagi\n",
    "    * konieczne dodanie jakiegoś _weight decay_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
