{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "<big><big><big><big><big><big>Sieci neuronowe 2018/19</big></big></big></big></big></big>\n",
    "\n",
    "---\n",
    "<big><big><big><big><big>Sieci konwolucyjne</big></big></big></big></big>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "\n",
    "from bokeh.io import gridplot, output_file, show\n",
    "from bokeh.plotting import figure, output_notebook\n",
    "from bkcharts import Scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sieci konwolucyjne\n",
    "wykorzystują __konwolucje__ zamiast mnożenia macierzy w co najmniej jednej z warstw\n",
    "* czym są _konwolucje_?\n",
    "* na czym polega _rzadkość_ sieci konwolucyjnych?\n",
    "* czym jest _pooling_?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noecognitron (Fukushima, 1980)\n",
    "<img src=\"../nn_figures/neocognitron.png\" width=\"70%\"> ['O'Reilly]\n",
    "1. na wejściu tzw. __retina__ odpowiedzialna za odbiór obrazu\n",
    "2. hierarchicznie ułożone warstwy __S _oraz_ C__ \n",
    "  * __S__-warstwy (S jak simple) odpowiedzialne za ekstrakcję cech\n",
    "    * zmienne wejścia modyfikowane poprzez uczenie\n",
    "    * po zakończeniu uczenia każda s-komórka staje się _ekstraktorem_ pewnej konkretnej cechy w polu widzenia (reaguje na jej pojawienie się)\n",
    "      * uczenie odpowiada wyborowi wykrywanej cechy\n",
    "    * cechy bardziej lokalne są wykrywane bliżej wejścia modelu, te bardziej globalne później\n",
    "  * __C__-warstwy (C jak complex) \n",
    "    * pozwalają na korekcję błędów translacji na wejściu\n",
    "    * wejścia do C-komórek z ekstraktorów w warstwach S są ustalone i niezmienne\n",
    "    * każda C-komórka dostaje wejście z grupy S-komórek wykrywających __tą samą__ cechę ale niewiele różniących się pozycjach - zapewnia inwariantność na translacje\n",
    "    * C-komórka jest aktywowana jeśli co najmniej jedna S-komórka wykryła cechę\n",
    "3. warstwy S i C przypominają komórki w układzie widzenia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../nn_figures/neocognitron2.gif\" width=\"50%\"> [Fukushima, ScholarPedia]\n",
    "1. Sieć uczy się w procesie __samo-organizacji__\n",
    "  * tylko S-komórki mają modyfikowane wagi\n",
    "  * __winner-take-all__ wśród komórek w małym określonym obszarze (tzw. kolumnie) tylko jedna staje się zwycięzcą i jest aktywowana\n",
    "    * połączenia zwycięzcy są wzmacniane\n",
    "    * siła wzmocnienia jest proporcjonalna do aktywacji\n",
    "    * na początku wszystkie połączenia są bardzo słabe\n",
    "    * po jakimś czasie S-komórki uczą się rozpoznawać pewne wzorce\n",
    "  * wszystkie komórki z otoczenia zwycięzcy podążają za nim\n",
    "<img src=\"../nn_figures/neocognitron4.gif\" width=\"70%\"> [Fukushima, ScholarPedia]\n",
    "2. Neocognitron osiąga na zbiorze MNIST błąd rzędu 2.5%\n",
    "3. Nauczanie jest niezależne dla każdej warstwy\n",
    "  * istotne stają się wielkości komórek C i S, co utrudnia uczenie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet5 (LeCun 1998)\n",
    "<img src=\"../nn_figures/lenet5.pdf\" width=\"100%\">[LeCun NIPS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konwolucje\n",
    "1. dla dwu-wymiarowych obrazów $I$ można zdefiniować 2-wymiarowe kernele $K$ tak, że __dyskretna__ konwolucja będzie zdefiniowana jako\n",
    "$$S(i,j)=(I*K)(i,j)=\\sum_m\\sum_nI(m,n)K(i-m,j-n)$$\n",
    "2. konwolucje są komutatywne, skąd\n",
    "$$S(i,j)=(K*I)(i,j)=\\sum_m\\sum_nI(i-m,j-n)K(m,n)$$\n",
    "  * ten opis jest dla obrazów bardziej oczywisty \n",
    "  * zwykle implementowany implementowany będzie schemat korelacji\n",
    "  $$S(i,j)=(I*K)(i,j)=\\sum_m\\sum_nI(i+m,j+n)K(m,n)$$\n",
    "  dający ten sam wynik\n",
    "  * macierz kernela jest _rzadka_: zerowa wszędzie poza polami leżącymi na obrazie\n",
    "3. praktycznie można pojrzeć na obliczanie konwolucji jako mnożenie macierzy\n",
    "  * konwolucje dyskretne w CNN są na ograniczonym zakresie - rozmiarze kernela"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### co dają konwolucje?\n",
    "* __rzadkie interakcje__\n",
    "  * w sieciach warstwowych każdy element wyjściowy jest połączony z każdym wejściowym przez jakiś parametr\n",
    "  * kernel jest __mniejszy__ niż wejście\n",
    "  * zwiększa wydajność\n",
    "  * te same cechy są wykrywane w różnych miejscach\n",
    "  * w głębokich sieciach neurony w głębszych warstwach współpracują z większymi obszarami wejścia\n",
    "* __współdzielenie parametrów__\n",
    "  * w modelach warstwowych każda waga jest użyta __dokładnie raz__ przy liczeniu wyjścia\n",
    "  * w sieci konwolucyjnej każda waga kernela jest użyta dla __każdego__ elementu wejścia (ew. poza obszarami na brzegu)\n",
    "    * zamiast uczyć zestawu wag dla każdego wejścia, uczony jest __jeden__ zestaw\n",
    "* __równoważne reprezentacje__\n",
    "  * utworzone reprezentacje $f$ stają się odporne na translacje $t$, bo $f(t(x))=t(f(x))$\n",
    "  * kernel wykrywający brzegi będzie do zastosowania w różnych miejscach obrazu\n",
    "* oszczędność\n",
    "  * pamięciową przez dzielenie parametrów\n",
    "  * obliczeniową dzięki lokalności\n",
    "* czy jednak sieci konwolucyjne mają taką samą moc obliczeniową jak sieci warstwowe na takich samych obrazach?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling\n",
    "<img src=\"../nn_figures/cnn.pdf\" width=\"70%\"> [Goodfellow et al.]\n",
    "1. typowa warstwa sieci CNN składa się z\n",
    "  * szeregu __konwolucji__ tworzących liniowe aktywacje\n",
    "  * __nieliniowych aktywacji__ dla wykrywania (detekcji) cech (features)\n",
    "  * modyfikacji przez __pooling__\n",
    "2. pooling __zastępuje__ wartość w danym miejscu pewną statystyką dla obszaru wokół\n",
    "  * __max pooling__ zwraca maksymalną wartość dla pewnego prostokątnego obszaru\n",
    "    * każde pole tego obszaru może odpowiadać nieco różnej wykrytej cesze\n",
    "  * __average pooling__ zwraca średnią\n",
    "  * __L2 norm pooling__ normą kwadratową dla prostokątnego obszaru\n",
    "  * __weighted pooling__ ważoną średnią odległość od piksela w centrum obszaru\n",
    "3. max pooling wprowadza pewną inwariantność na translację\n",
    "  * niewielkie przesunięcie wejścia może zmienić tylko niewielką część wyjścia\n",
    "  * także pewną inwariantność na powiększenie\n",
    "  * pooling zmniejsza rozmiar przetwarzanego obszaru\n",
    "    * w kolejnych warstwach przetwarzane są cechy wyższego poziomu\n",
    "    * także efektywniejsze obliczeniowo\n",
    "4. można rozróżnić dwa typy\n",
    "  * pooling przestrzenny\n",
    "  * pooling po kanałach\n",
    "    * koncepcyjnie przypomina aktywacje _max out_ (Goodfellow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konwolucje w modelach sieci neuronowych\n",
    "1. konwolucja z __jednym__ kernelem wykrywa tylko __jedną__ cechę (feature), chociaż w wielu miejscach\n",
    "  * w sieciach neuronowych potrzebujemy wykrywać __wiele różnych__ cech w wielu miejscach\n",
    "2. wejściowy obraz składa się zwykle z wektorów obserwacji w każdym punkcie\n",
    "  * np. obraz RGB\n",
    "  * wejściem do konwolucji w kolejnej warstwie są wyjścia konwolucji poprzedniej \n",
    "  * dla obrazów wejścia i wyjścia są tensorami 3-D\n",
    "    * jeden indeks to kanał\n",
    "    * dwa indeksy podają współrzędne\n",
    "  * w rzeczywistości 4-D tensory: jeszcze indeks pozycji w batchu\n",
    "3. __stride__ określa przesunięcie ponad niektórymi cechami obrazu wejściowego\n",
    "  * konwolucja ze stride jest równoważna pełnej konwolucji z downsamplingiem bezpośrednio później\n",
    "4. __padding__ pozwala na kontrolę szerokości obrazu w kolejnych warstwach\n",
    "  * bez paddingu obraz zmniejsza się co najmniej o piksel na warstwę\n",
    "  * bez paddingu albo obraz szybko się zmniejsza albo potrzebne jest użycie małych kerneli\n",
    "    * oba rozwiązania są niedobre\n",
    "  * padding jest realizowany zwykle przez dodanie zerowych pikseli\n",
    "    * możliwe także dodanie np. lustrzanego odbicia\n",
    "5. możliwe alternatywy\n",
    "  * __no (valid) padding__ i pixele kernela __nie mogą__ wychodzić poza obszar obrazu\n",
    "    * wszystkie piksele wyjścia są funkcją __tej samej__ liczby pikseli wejścia\n",
    "    * każda kolejna warstwa zmniejsza się\n",
    "    \n",
    "    <img width=\"150px\" src=\"../nn_figures/no_padding_no_strides.gif\"><img width=\"150px\" src=\"../nn_figures/no_padding_strides.gif\">[Dumoulin, Visin, arXiv:1603.07285]\n",
    "    * liczba pikseli wyjściowych wynosi (dla $s=1$) $$o=(i-k)+2p+1$$\n",
    "    * dla $s>1$ liczba pikseli wyjściowych $$o=\\left\\lfloor\\frac{i-k}{s}\\right\\rfloor+1$$\n",
    "  * __same (half) padding__ zapewnia tyle dodanych pikseli by warstwy __nie zmniejszały__ się\n",
    "    * może być dowolna liczba warstw konwolucji\n",
    "    * piksele blisko brzegu wpływają na mniej pikseli wyjściowych\n",
    "    \n",
    "    <img width=\"150px\" src=\"../nn_figures/same_padding_no_strides.gif\">[Dumoulin, Visin, arXiv:1603.07285]\n",
    "    * liczba pikseli wyjściowych (dla $s=1, k=2n+1, p=\\lfloor{}k/2\\rfloor$) to $$o=i+2\\lfloor{}k/2\\rfloor-(k-1)=i+2n-2n=i$$\n",
    "  * __full padding__ gdzie dodane jest tyle zer, by każdy piksel obrazu był odwiedzony tą samą liczbę razy\n",
    "    * każdy __wyjściowy__ piksel blisko brzegu jest funkcją mniejszej liczby pikseli wejściowych\n",
    "    \n",
    "    <img width=\"150px\" src=\"../nn_figures/full_padding_no_strides.gif\">[Dumoulin, Visin, arXiv:1603.07285]\n",
    "    * liczba pikseli wyjściowych (dla $p=k-1, s=1$) to $$o=i+2(k-1)-(k-1)=i+(k-1)$$\n",
    "    \n",
    "    <img width=\"150px\" src=\"../nn_figures/padding_strides.gif\"><img width=\"150px\" src=\"../nn_figures/padding_strides_odd.gif\">[Dumoulin, Visin, arXiv:1603.07285]\n",
    "  * w ogólnym przypadku liczba wyjściowych to $$o=\\left\\lfloor\\frac{i+2p-k}{s}\\right\\rfloor+1$$\n",
    "6. zwykle optymalne rozwiązanie leży gdzieś między _valid_ a _same_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling\n",
    "1. warstwy pooling zapewniają pewne niewielkie inwariancje na translacje wejścia\n",
    "2. __max pooling__ \n",
    "  * dzieli wejście na patche\n",
    "    * zwykle __nie__ nakładające się\n",
    "  * wybraniu maksymalnej wartości\n",
    "3. pooling nie wykorzystuje paddowania, a więc $$o=\\left\\lfloor\\frac{i-k}{s}\\right\\rfloor+1$$\n",
    "  * a więc tak samo jak konwolucje bez paddingu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dekonwolucje\n",
    "1. a gdybyśmy chcieli odzyskać widzialne obrazy z głębokich reprezentacji?\n",
    "  * prostym rozwiązaniem jest mnożenie przez __transpozycję__ macierzy konwolucji\n",
    "  * modele auto-enkoderów, RBM, itp.\n",
    "2. jest to jednak trochę bardziej złożone niż w modelach warstwowych\n",
    "3. konwolucje __transponowane__\n",
    "\n",
    "  <img width=\"150px\" src=\"../nn_figures/no_padding_no_strides.gif\"><img width=\"150px\" src=\"../nn_figures/no_padding_no_strides_transposed.gif\">[Dumoulin, Visin, arXiv:1603.07285]\n",
    "  * konwolucja $3\\times3$ nad wejsciem $4\\times4$ bez paddingu ($p=0$) i jednostkowym stridem (tzn. $s=1$)\n",
    "  * równoważne konwolucji $3\\times3$ nad wejściem $2\\times2$ wypadowane z każdej strony pasem $2$ pikseli ($p=2$) z jednostkowym strajdem ($s=1$)\n",
    "  * jednak narożne piksele wejścia wpływają __jedynie__ na naróżne piksele odtwarzanego obrazu\n",
    "    * paddowanie ma wymiar $p=k-1$\n",
    "    * stąd wymiar wyjściowy to $o'=i'+(k-1)$\n",
    "  * takie transponowane konwolucje zresztą jedynie odtwarzają __kształt__, a nie ma tu żadnej pewności odtwarzania wejścia\n",
    "4. konwolucje strajdowane __cząstkowo__ (_ang_. __fractionally__)\n",
    "  * czy możemy sobie wyobrazić sytuację z $s<1$??\n",
    "  \n",
    "  <img width=\"150px\" src=\"../nn_figures/no_padding_strides_transposed.gif\"><img width=\"150px\" src=\"../nn_figures/padding_strides_transposed.gif\">[Dumoulin, Visin, arXiv:1603.07285]\n",
    "  * wyjście będzie miało wymiar $$o'=s(i'-1)+k$$ gdzie $p'=k-1$ a rozszerzone wejście $i'$ jest uzyskane przez dodanie $s-1$ pasów zer miedzy wszystkimi zerami/kolumnami"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konwolucje rozmyte (dilated)\n",
    "1. albo __atrous__ z francuskiego ___a trous___ (_z dziurami_)\n",
    "2. rozmyciu ulega kernel przez dodanie spacji pomiędzy elementy jądra\n",
    "  * dodawane jest $d-1$ rzędów/wierszy spacji, gdzie $d=1$ odpowiada konwolucji nierozmytej\n",
    "  * rozmycie kernela sztucznie zwiększa jego wymiar do $$k'=k+(k-1)(d-1)$$\n",
    "  <img width=\"150px\" src=\"../nn_figures/dilation.gif\">[Dumoulin, Visin, arXiv:1603.07285]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konwolucje tiled\n",
    "1. składają się z kilku konwolucji sąsiadujących\n",
    "  * konwolucje są osobne\n",
    "  * mają różne parametry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uczenie sieci CNN\n",
    "1. każdy kernel jest odpowiedzialny za wykrywanie pewnej cechy\n",
    "2. okazuje się, że wsteczna propagacja jest __wystarczająca__\n",
    "  * konwolucja\n",
    "  * wsteczna propagacja od wyjścia do wag\n",
    "  * wsteczna propagacja od wyjscia do wejścia\n",
    "  \n",
    "  są wystarczające dla nauczenie dowolnej sieci CNN z propagacją wprzód\n",
    "  \n",
    "3. __bias__ jest także elementem sieci CNN\n",
    "  * w sieciach warstwowych typowy bias jest związany z każdym neuronem\n",
    "  * w CNN każdy bias jest typowo związany z każdym kanałem\n",
    "    * możliwe jest rozróżnienie biasu dla różnych położeń obrazu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageNet: Alex net\n",
    "<img src=\"../nn_figures/imagenet.pdf\" width=\"80%\">[Krizhevsky, Sutskever, Hinton NIPS]\n",
    "1. Konkurs ILSVRC'2010 (ImageNet Large-Scale Visual Recognition Challenge)\n",
    "  * oryginalny zbiór danych ma ponad 22 miliony obrazów etykietowanych ponad 22 tysiącami klas\n",
    "  * zbiór danych konkursu to 1.2 miliona obrazów z 1000 różnych klas\n",
    "  * 50 tysięcy walidacyjnych, 150 tysięcy testowych\n",
    "  * obrazy różnych rozdzielczości przeskalowane i wycięte do $256\\times256$\n",
    "    * w końcowym uczeniu użyte obrazy $224\\times224$\n",
    "  * dwie miary błędów\n",
    "    * __top-1__ binarna miara prawidłowa/nieprawidłowa\n",
    "    * __top-5__ że prawidłowa etykieta __jest/nie jest__ wśród 5-ciu zaproponowanych\n",
    "  * problem uczony na danych __jedynie__ z odjętą średnią dla każdego piksela/kanału\n",
    "2. wyniki\n",
    "  * top-1 37.5\\% błędów\n",
    "  * top-5 17.0\\% błędów\n",
    "    * jedna z wersji osiągnęła 15.3\\% w top-5\n",
    "    * drugi najlepszy miał w top-5 26.2\\% błędów"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
